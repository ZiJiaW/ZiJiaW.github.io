<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Hugo 0.80.0" />

  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="一只特立独行的猫" />
  <meta property="og:url" content="https://zijiaw.github.io/posts/a9-xgboost/" />
  <link rel="canonical" href="https://zijiaw.github.io/posts/a9-xgboost/" /><link rel="alternate" type="application/atom+xml" href="https://zijiaw.github.io/index.xml" title="一只特立独行的猫">

  <script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "https:\/\/zijiaw.github.io\/"
      },
      "articleSection" : "posts",
      "name" : "算法拾遗：XGBoost",
      "headline" : "算法拾遗：XGBoost",
      "description" : "本文介绍XGBoost的基本思想。\n一个包含$K$树棵的集成模型中，每棵树的预测结果是一个实数值（回归树），如果我们把每棵树看作是一个函数$f_k$，则对于样本$x_i$的预测结果为这些树的输出之和： $$\\hat y_i=\\phi(x_i)=\\sum_{k=1}^K f_k(x_i)$$ 我们的目标就是求解最优的$K$棵树。\n对于树模型来说，假设有$T$个叶子结点，每棵树会把输入$x$映射到某一个叶子结点$q(x)$上，并输出该叶子节点上预设的值$w_{q(x)}$。上面用$q$来表示一棵树形成的独特映射（将输入映射到叶子结点），而$w$表示叶子结点上的值向量，这二者实际上就代表了一棵树。\n现在我们考虑这样一个模型的损失函数： $$L(\\phi)=\\sum_il(\\hat y_i,y_i) \u002b \\sum_{k=1}^K \\Omega(f_k)$$ 其中第一项为所有样本上的误差之和，比如平方误差；后一项为正则项，用于限制每棵树的复杂度，复杂度越大惩罚越大，其定义为： $$\\Omega(f_k)=\\gamma T\u002b\\frac{1}{2} \\lambda ||w||^2$$ 可以看到其实际上为叶子节点数量$T$与权重$w$的平方和的加权和。\n我们使用迭代的策略来一棵一棵计算上面的树模型，假设在第$t$轮添加的树对应函数为$f_t$，则在前$t-1$棵树已经确定的情况下，损失函数为： $$L(\\phi_t)=\\sum_i l(\\hat y_i^{(t-1)}\u002bf_t(x_i),y_i)\u002b\\Omega(f_t)$$ 其中$\\hat y_i^{(t-1)}$为前$t-1$棵树的预测结果。我们需要在第$t$轮计算一棵最小化$L(\\phi_t)$的树，贪心地加入到模型中。\n上面式中，变量为$f_t(x_i)$，我们将函数$l(\\hat y_i^{(t-1)}\u002bf_t(x_i),y_i)$在$\\hat y_i^{(t-1)}$处展开到二阶泰勒来近似： $$l(\\hat y_i^{(t-1)}\u002bf_t(x_i),y_i)\\approx l(\\hat y_i^{(t-1)},y_i)\u002bg_if_t(x_i)\u002b\\frac{1}{2}h_if_t^2(x_i)$$ 其中$g_i$和$h_i$分别是损失函数$l(a, y_i)$在$a=\\hat y_i^{(t-1)}$处的一阶和二阶导数。\n经过近似，我们去掉式中的常量部分，即$l(\\hat y_i^{(t-1)},y_i)$，将需最小化的损失函数修改为： $$L(\\phi_t)\\approx \\sum_{i=1}^n[g_if_t(x_i)\u002b\\frac{1}{2}h_if_t^2(x_i)]\u002b\\gamma T\u002b\\frac{1}{2}\\lambda\\sum_{j=1}^Tw_j^2$$ 现在我们已经将$f_t$单独拿了出来，现在考虑$\\sum_i f_t(x_i)$是什么？\n如果$q(x_i)=j$，那么$f_t(x_i)=w_j$，因此假如集合$I_j$是所有被树映射到叶子节点$j$的样本集合，即$I_j={i| q(x_i)=j}$，那么： $$\\sum_if_t(x_i)=\\sum_{j=1}^T w_j|I_j|$$ 因此损失函数可以变化为： $$L(\\phi_t)=\\sum_{j=1}^T \\big[(\\sum_{i\\in I_j} g_i)w_j\u002b\\frac{1}{2}(\\lambda\u002b\\sum_{i\\in I_j}h_i)w_j^2\\big]\u002b\\gamma T$$ 上面的式子中，我们可以很快看出每个叶子结点的权值$w_j$的最优取值为： $$w_j^*=-\\frac{\\sum_{i\\in I_j} g_i}{\\lambda\u002b\\sum_{i\\in I_j}h_i}$$ 上式中，$I_j$取决于当前树的结构，而其余部分均为已知的常值，也就是说，如果第$t$棵树的结构确定下来了，那么叶子节点的输出也可以按照上式直接计算出来。\n我们将$w$代入损失函数： $$L(\\phi_t)=-\\frac{1}{2}\\sum_{j=1}^T \\frac{(\\sum_{i\\in I_j} g_i)^2}{\\lambda\u002b\\sum_{i\\in I_j}h_i}\u002b\\gamma T$$ 上式给出了一个确定结构的回归树加入后整个模型的损失函数，我们需要构造一棵最小化上式的树。\n我们考虑迭代方式构造树，从根节点开始尝试对叶子结点增加分支，假如对叶子结点$j$增加分支，对映射到该结点的样本再进行划分，将$I_j$划分为$I_l$和$I_r$，作为新的两个叶子结点，而其余结点没有变化，那么新树的损失函数为： $$L_{new}=\\gamma \u002b L \u002b\\frac{1}{2}\\Big(\\frac{(\\sum_{i\\in I_j} g_i)^2}{\\lambda\u002b\\sum_{i\\in I_j}h_i}-\\frac{(\\sum_{i\\in I_l} g_i)^2}{\\lambda\u002b\\sum_{i\\in I_l}h_i}-\\frac{(\\sum_{i\\in I_r} g_i)^2}{\\lambda\u002b\\sum_{i\\in I_r}h_i}\\Big)$$ 显然，我们希望划分后产生的新树的损失函数最小，实际上就是要找到一个最优的划分，使得上式最小化，如果把对应结点的式子看作该结点的score，那么就是需要新结点的score之和最大。如果上式最小化后，$L_{new}\u0026gt;=L$，则显然在结点$j$处不可再划分了。",
      "inLanguage" : "en-US",
      "author" : "一只特立独行的猫",
      "creator" : "一只特立独行的猫",
      "publisher": "一只特立独行的猫",
      "accountablePerson" : "一只特立独行的猫",
      "copyrightHolder" : "一只特立独行的猫",
      "copyrightYear" : "2022",
      "datePublished": "2022-06-20 00:00:00 \u002b0000 UTC",
      "dateModified" : "2022-06-20 00:00:00 \u002b0000 UTC",
      "url" : "https:\/\/zijiaw.github.io\/posts\/a9-xgboost\/",
      "keywords" : [  ]
  }
</script>
<title>算法拾遗：XGBoost</title>
  <meta property="og:title" content="算法拾遗：XGBoost" />
  <meta property="og:type" content="article" />
  <meta property="og:description" content="本文介绍XGBoost的基本思想。
一个包含$K$树棵的集成模型中，每棵树的预测结果是一个实数值（回归树），如果我们把每棵树看作是一个函数$f_k$，则对于样本$x_i$的预测结果为这些树的输出之和： $$\hat y_i=\phi(x_i)=\sum_{k=1}^K f_k(x_i)$$ 我们的目标就是求解最优的$K$棵树。
对于树模型来说，假设有$T$个叶子结点，每棵树会把输入$x$映射到某一个叶子结点$q(x)$上，并输出该叶子节点上预设的值$w_{q(x)}$。上面用$q$来表示一棵树形成的独特映射（将输入映射到叶子结点），而$w$表示叶子结点上的值向量，这二者实际上就代表了一棵树。
现在我们考虑这样一个模型的损失函数： $$L(\phi)=\sum_il(\hat y_i,y_i) &#43; \sum_{k=1}^K \Omega(f_k)$$ 其中第一项为所有样本上的误差之和，比如平方误差；后一项为正则项，用于限制每棵树的复杂度，复杂度越大惩罚越大，其定义为： $$\Omega(f_k)=\gamma T&#43;\frac{1}{2} \lambda ||w||^2$$ 可以看到其实际上为叶子节点数量$T$与权重$w$的平方和的加权和。
我们使用迭代的策略来一棵一棵计算上面的树模型，假设在第$t$轮添加的树对应函数为$f_t$，则在前$t-1$棵树已经确定的情况下，损失函数为： $$L(\phi_t)=\sum_i l(\hat y_i^{(t-1)}&#43;f_t(x_i),y_i)&#43;\Omega(f_t)$$ 其中$\hat y_i^{(t-1)}$为前$t-1$棵树的预测结果。我们需要在第$t$轮计算一棵最小化$L(\phi_t)$的树，贪心地加入到模型中。
上面式中，变量为$f_t(x_i)$，我们将函数$l(\hat y_i^{(t-1)}&#43;f_t(x_i),y_i)$在$\hat y_i^{(t-1)}$处展开到二阶泰勒来近似： $$l(\hat y_i^{(t-1)}&#43;f_t(x_i),y_i)\approx l(\hat y_i^{(t-1)},y_i)&#43;g_if_t(x_i)&#43;\frac{1}{2}h_if_t^2(x_i)$$ 其中$g_i$和$h_i$分别是损失函数$l(a, y_i)$在$a=\hat y_i^{(t-1)}$处的一阶和二阶导数。
经过近似，我们去掉式中的常量部分，即$l(\hat y_i^{(t-1)},y_i)$，将需最小化的损失函数修改为： $$L(\phi_t)\approx \sum_{i=1}^n[g_if_t(x_i)&#43;\frac{1}{2}h_if_t^2(x_i)]&#43;\gamma T&#43;\frac{1}{2}\lambda\sum_{j=1}^Tw_j^2$$ 现在我们已经将$f_t$单独拿了出来，现在考虑$\sum_i f_t(x_i)$是什么？
如果$q(x_i)=j$，那么$f_t(x_i)=w_j$，因此假如集合$I_j$是所有被树映射到叶子节点$j$的样本集合，即$I_j={i| q(x_i)=j}$，那么： $$\sum_if_t(x_i)=\sum_{j=1}^T w_j|I_j|$$ 因此损失函数可以变化为： $$L(\phi_t)=\sum_{j=1}^T \big[(\sum_{i\in I_j} g_i)w_j&#43;\frac{1}{2}(\lambda&#43;\sum_{i\in I_j}h_i)w_j^2\big]&#43;\gamma T$$ 上面的式子中，我们可以很快看出每个叶子结点的权值$w_j$的最优取值为： $$w_j^*=-\frac{\sum_{i\in I_j} g_i}{\lambda&#43;\sum_{i\in I_j}h_i}$$ 上式中，$I_j$取决于当前树的结构，而其余部分均为已知的常值，也就是说，如果第$t$棵树的结构确定下来了，那么叶子节点的输出也可以按照上式直接计算出来。
我们将$w$代入损失函数： $$L(\phi_t)=-\frac{1}{2}\sum_{j=1}^T \frac{(\sum_{i\in I_j} g_i)^2}{\lambda&#43;\sum_{i\in I_j}h_i}&#43;\gamma T$$ 上式给出了一个确定结构的回归树加入后整个模型的损失函数，我们需要构造一棵最小化上式的树。
我们考虑迭代方式构造树，从根节点开始尝试对叶子结点增加分支，假如对叶子结点$j$增加分支，对映射到该结点的样本再进行划分，将$I_j$划分为$I_l$和$I_r$，作为新的两个叶子结点，而其余结点没有变化，那么新树的损失函数为： $$L_{new}=\gamma &#43; L &#43;\frac{1}{2}\Big(\frac{(\sum_{i\in I_j} g_i)^2}{\lambda&#43;\sum_{i\in I_j}h_i}-\frac{(\sum_{i\in I_l} g_i)^2}{\lambda&#43;\sum_{i\in I_l}h_i}-\frac{(\sum_{i\in I_r} g_i)^2}{\lambda&#43;\sum_{i\in I_r}h_i}\Big)$$ 显然，我们希望划分后产生的新树的损失函数最小，实际上就是要找到一个最优的划分，使得上式最小化，如果把对应结点的式子看作该结点的score，那么就是需要新结点的score之和最大。如果上式最小化后，$L_{new}&amp;gt;=L$，则显然在结点$j$处不可再划分了。" />
  <meta name="description" content="本文介绍XGBoost的基本思想。
一个包含$K$树棵的集成模型中，每棵树的预测结果是一个实数值（回归树），如果我们把每棵树看作是一个函数$f_k$，则对于样本$x_i$的预测结果为这些树的输出之和： $$\hat y_i=\phi(x_i)=\sum_{k=1}^K f_k(x_i)$$ 我们的目标就是求解最优的$K$棵树。
对于树模型来说，假设有$T$个叶子结点，每棵树会把输入$x$映射到某一个叶子结点$q(x)$上，并输出该叶子节点上预设的值$w_{q(x)}$。上面用$q$来表示一棵树形成的独特映射（将输入映射到叶子结点），而$w$表示叶子结点上的值向量，这二者实际上就代表了一棵树。
现在我们考虑这样一个模型的损失函数： $$L(\phi)=\sum_il(\hat y_i,y_i) &#43; \sum_{k=1}^K \Omega(f_k)$$ 其中第一项为所有样本上的误差之和，比如平方误差；后一项为正则项，用于限制每棵树的复杂度，复杂度越大惩罚越大，其定义为： $$\Omega(f_k)=\gamma T&#43;\frac{1}{2} \lambda ||w||^2$$ 可以看到其实际上为叶子节点数量$T$与权重$w$的平方和的加权和。
我们使用迭代的策略来一棵一棵计算上面的树模型，假设在第$t$轮添加的树对应函数为$f_t$，则在前$t-1$棵树已经确定的情况下，损失函数为： $$L(\phi_t)=\sum_i l(\hat y_i^{(t-1)}&#43;f_t(x_i),y_i)&#43;\Omega(f_t)$$ 其中$\hat y_i^{(t-1)}$为前$t-1$棵树的预测结果。我们需要在第$t$轮计算一棵最小化$L(\phi_t)$的树，贪心地加入到模型中。
上面式中，变量为$f_t(x_i)$，我们将函数$l(\hat y_i^{(t-1)}&#43;f_t(x_i),y_i)$在$\hat y_i^{(t-1)}$处展开到二阶泰勒来近似： $$l(\hat y_i^{(t-1)}&#43;f_t(x_i),y_i)\approx l(\hat y_i^{(t-1)},y_i)&#43;g_if_t(x_i)&#43;\frac{1}{2}h_if_t^2(x_i)$$ 其中$g_i$和$h_i$分别是损失函数$l(a, y_i)$在$a=\hat y_i^{(t-1)}$处的一阶和二阶导数。
经过近似，我们去掉式中的常量部分，即$l(\hat y_i^{(t-1)},y_i)$，将需最小化的损失函数修改为： $$L(\phi_t)\approx \sum_{i=1}^n[g_if_t(x_i)&#43;\frac{1}{2}h_if_t^2(x_i)]&#43;\gamma T&#43;\frac{1}{2}\lambda\sum_{j=1}^Tw_j^2$$ 现在我们已经将$f_t$单独拿了出来，现在考虑$\sum_i f_t(x_i)$是什么？
如果$q(x_i)=j$，那么$f_t(x_i)=w_j$，因此假如集合$I_j$是所有被树映射到叶子节点$j$的样本集合，即$I_j={i| q(x_i)=j}$，那么： $$\sum_if_t(x_i)=\sum_{j=1}^T w_j|I_j|$$ 因此损失函数可以变化为： $$L(\phi_t)=\sum_{j=1}^T \big[(\sum_{i\in I_j} g_i)w_j&#43;\frac{1}{2}(\lambda&#43;\sum_{i\in I_j}h_i)w_j^2\big]&#43;\gamma T$$ 上面的式子中，我们可以很快看出每个叶子结点的权值$w_j$的最优取值为： $$w_j^*=-\frac{\sum_{i\in I_j} g_i}{\lambda&#43;\sum_{i\in I_j}h_i}$$ 上式中，$I_j$取决于当前树的结构，而其余部分均为已知的常值，也就是说，如果第$t$棵树的结构确定下来了，那么叶子节点的输出也可以按照上式直接计算出来。
我们将$w$代入损失函数： $$L(\phi_t)=-\frac{1}{2}\sum_{j=1}^T \frac{(\sum_{i\in I_j} g_i)^2}{\lambda&#43;\sum_{i\in I_j}h_i}&#43;\gamma T$$ 上式给出了一个确定结构的回归树加入后整个模型的损失函数，我们需要构造一棵最小化上式的树。
我们考虑迭代方式构造树，从根节点开始尝试对叶子结点增加分支，假如对叶子结点$j$增加分支，对映射到该结点的样本再进行划分，将$I_j$划分为$I_l$和$I_r$，作为新的两个叶子结点，而其余结点没有变化，那么新树的损失函数为： $$L_{new}=\gamma &#43; L &#43;\frac{1}{2}\Big(\frac{(\sum_{i\in I_j} g_i)^2}{\lambda&#43;\sum_{i\in I_j}h_i}-\frac{(\sum_{i\in I_l} g_i)^2}{\lambda&#43;\sum_{i\in I_l}h_i}-\frac{(\sum_{i\in I_r} g_i)^2}{\lambda&#43;\sum_{i\in I_r}h_i}\Big)$$ 显然，我们希望划分后产生的新树的损失函数最小，实际上就是要找到一个最优的划分，使得上式最小化，如果把对应结点的式子看作该结点的score，那么就是需要新结点的score之和最大。如果上式最小化后，$L_{new}&amp;gt;=L$，则显然在结点$j$处不可再划分了。" />
  <meta property="og:locale" content="zh-cn" />

  
    <style>body{font-family:bree serif,sans-serif;-webkit-font-smoothing:antialiased;margin:0 20px}article{max-width:800px;margin-left:auto;margin-right:auto}a{color:#000;text-decoration:none}a:hover{font-weight:600;text-decoration:underline}.post-ads{margin:50px 0}.markdown-body{font-size:18px;max-width:100%}.markdown-body a{text-decoration:underline;text-decoration-color:#000}.markdown-body pre{padding:16px;overflow:auto;border-radius:10px}.markdown-body code{padding:.2em .4em;font-size:85%;background-color:#f6f8fa;border-radius:6px}.markdown-body pre>code{padding:0;font-size:100%;background-color:inherit;border:0}.Chinese .markdown-body{line-height:200%}.site-date-catalog{font-size:2rem}.header-title{font-size:2rem;font-weight:700;margin-top:32px;font-family:bungee shade,sans-serif}.header-title a{text-decoration:none}.header-subtitle{color:#666}.header-items{margin:10px 0}.header-item{margin:0 5px}.header-line{width:100%;border-width:2px;border-color:#482936;border-style:solid none none none}.lang-switch{font-weight:600}#posts-list{min-height:600px}.posts-date,.posts-title{font-size:1.2rem}.posts-line{margin:12px 0}.posts-categories{font-size:.8rem;margin:auto;text-align:center}.posts-category{padding:3px 0;border:#000 2px solid;border-radius:5px;margin-bottom:3px}.site-footer{margin-top:50px}.site-footer-item{margin-right:12px}@media screen and (max-width:600px){.header-title,.header-subtitle,.header-items{text-align:center}.post-content{padding:0 12px}.post-content p{letter-spacing:.05em}}@media screen and (max-width:48em){.posts-category{display:none}}.post-content img{max-width:100%;display:block;margin-left:auto;margin-right:auto;margin-top:12px}.post-header{margin-bottom:50px}.post-title{font-size:2.5rem;font-weight:600}.post-category{display:inline;font-weight:900;padding:2px 5px;border:#000 2px solid;border-radius:5px}.post-date{font-weight:800;font-style:italic}.post-author{float:right;font-weight:600}.page-content{min-height:60%}.post-content{margin-bottom:50px}.post-content p{hyphens:auto;line-height:1.8;text-justify:ideographic;margin-bottom:1em}.related-content{border-width:3px;border-style:solid;border-color:#000;padding:0 10px;margin-bottom:50px;margin-top:100px}.related-content li{margin:5px 0}.taxonomy-term{font-size:3rem}.gallery-img{text-align:center}.gallery-img span{text-align:center}.gallery-img-desc{font-size:.8em;font-weight:800}#disqus_thread{position:relative}#disqus_thread:after{content:"";display:block;height:55px;width:100%;position:absolute;bottom:0;background:#fff}</style>
  
  
    <style>.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 1 auto;flex:0 1 auto;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse}.col.reverse{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;padding-right:.5rem;padding-left:.5rem}.col-xs{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-xs-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-xs-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-xs-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-xs-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-xs{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-xs{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-xs{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-xs{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-xs{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-xs{-ms-flex-pack:distribute;justify-content:space-around}.between-xs{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-xs{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-xs{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;padding-right:.5rem;padding-left:.5rem}.col-sm{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-sm-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-sm-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-sm-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-sm-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-sm{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-sm{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-sm{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-sm{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-sm{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-sm{-ms-flex-pack:distribute;justify-content:space-around}.between-sm{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-sm{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-sm{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-offset-0,.col-md-offset-1,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;padding-right:.5rem;padding-left:.5rem}.col-md{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-md-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-md-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-md-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-md-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-md{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-md{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-md{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-md{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-md{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-md{-ms-flex-pack:distribute;justify-content:space-around}.between-md{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-md{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-md{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;padding-right:.5rem;padding-left:.5rem}.col-lg{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-lg-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-lg-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-lg-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-lg-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-lg{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-lg{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-lg{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-lg{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-lg{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-lg{-ms-flex-pack:distribute;justify-content:space-around}.between-lg{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-lg{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-lg{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}</style>
  

  

  <link href="/index.xml" rel="alternate" type="application/rss+xml"
    title="一只特立独行的猫">
  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Bree+Serif|Bungee+Shade" rel="stylesheet">
  
  

  
  
</head>


<body>
  
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/katex.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/katex.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/contrib/auto-render.min.js"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
              delimiters: [
                  {left: "$$", right: "$$", display: true},
                  {left: "$", right: "$", display: false}
              ]
          });
    });
</script>
  <article class="post Chinese" id="article">
    <div class="row">
      <div class="col-xs-12">
        <div class="site-header">
          
<header>
  <div class="header-title">
    <a href="/"
      >一只特立独行的猫</a
    >
  </div>
  <div class="header-subtitle"></div>
</header>
<div class="row end-md center-xs header-items">
  
  <div class="header-item">
    <a href="https://github.com/ZiJiaW/" target="_blank">GitHub</a>
  </div>
  
  <div class="header-item">
    <a href="https://www.linkedin.com/in/zijia-wang-865a661a4/" target="_blank">LinkedIn</a>
  </div>
  
  <div class="header-item">
    <a href="mailto:zijiaw@outlook.com" target="_blank">Email</a>
  </div>
  
</div>
<div class="row end-xs">
   
</div>
<div class="header-line"></div>

        </div>
        <header class="post-header">
          <h1 class="post-title">算法拾遗：XGBoost</h1>
          
          <div class="row post-desc">
            <div class="col-xs-6">
              
              <time class="post-date" datetime="2022-06-20 00:00:00 UTC">
                20 Jun 2022
              </time>
              
            </div>
            <div class="col-xs-6">
              
              <div class="post-author">
                <a target="_blank" href="https://zijiaw.github.io/">@一只特立独行的猫</a>
              </div>
              
            </div>
          </div>
          
        </header>

        <div class="post-content markdown-body">
          
          <p>本文介绍XGBoost的基本思想。</p>
<p>一个包含$K$树棵的集成模型中，每棵树的预测结果是一个实数值（回归树），如果我们把每棵树看作是一个函数$f_k$，则对于样本$x_i$的预测结果为这些树的输出之和：
$$\hat y_i=\phi(x_i)=\sum_{k=1}^K f_k(x_i)$$
我们的目标就是求解最优的$K$棵树。</p>
<p>对于树模型来说，假设有$T$个叶子结点，每棵树会把输入$x$映射到某一个叶子结点$q(x)$上，并输出该叶子节点上预设的值$w_{q(x)}$。上面用$q$来表示一棵树形成的独特映射（将输入映射到叶子结点），而$w$表示叶子结点上的值向量，这二者实际上就代表了一棵树。</p>
<p>现在我们考虑这样一个模型的损失函数：
$$L(\phi)=\sum_il(\hat y_i,y_i) + \sum_{k=1}^K \Omega(f_k)$$
其中第一项为所有样本上的误差之和，比如平方误差；后一项为正则项，用于限制每棵树的复杂度，复杂度越大惩罚越大，其定义为：
$$\Omega(f_k)=\gamma T+\frac{1}{2} \lambda ||w||^2$$
可以看到其实际上为叶子节点数量$T$与权重$w$的平方和的加权和。</p>
<p>我们使用迭代的策略来一棵一棵计算上面的树模型，假设在第$t$轮添加的树对应函数为$f_t$，则在前$t-1$棵树已经确定的情况下，损失函数为：
$$L(\phi_t)=\sum_i l(\hat y_i^{(t-1)}+f_t(x_i),y_i)+\Omega(f_t)$$
其中$\hat y_i^{(t-1)}$为前$t-1$棵树的预测结果。我们需要在第$t$轮计算一棵最小化$L(\phi_t)$的树，贪心地加入到模型中。</p>
<p>上面式中，变量为$f_t(x_i)$，我们将函数$l(\hat y_i^{(t-1)}+f_t(x_i),y_i)$在$\hat y_i^{(t-1)}$处展开到二阶泰勒来近似：
$$l(\hat y_i^{(t-1)}+f_t(x_i),y_i)\approx l(\hat y_i^{(t-1)},y_i)+g_if_t(x_i)+\frac{1}{2}h_if_t^2(x_i)$$
其中$g_i$和$h_i$分别是损失函数$l(a, y_i)$在$a=\hat y_i^{(t-1)}$处的一阶和二阶导数。</p>
<p>经过近似，我们去掉式中的常量部分，即$l(\hat y_i^{(t-1)},y_i)$，将需最小化的损失函数修改为：
$$L(\phi_t)\approx \sum_{i=1}^n[g_if_t(x_i)+\frac{1}{2}h_if_t^2(x_i)]+\gamma T+\frac{1}{2}\lambda\sum_{j=1}^Tw_j^2$$
现在我们已经将$f_t$单独拿了出来，现在考虑$\sum_i f_t(x_i)$是什么？</p>
<p>如果$q(x_i)=j$，那么$f_t(x_i)=w_j$，因此假如集合$I_j$是所有被树映射到叶子节点$j$的样本集合，即$I_j={i| q(x_i)=j}$，那么：
$$\sum_if_t(x_i)=\sum_{j=1}^T w_j|I_j|$$
因此损失函数可以变化为：
$$L(\phi_t)=\sum_{j=1}^T \big[(\sum_{i\in I_j} g_i)w_j+\frac{1}{2}(\lambda+\sum_{i\in I_j}h_i)w_j^2\big]+\gamma T$$
上面的式子中，我们可以很快看出每个叶子结点的权值$w_j$的最优取值为：
$$w_j^*=-\frac{\sum_{i\in I_j} g_i}{\lambda+\sum_{i\in I_j}h_i}$$
上式中，$I_j$取决于当前树的结构，而其余部分均为已知的常值，也就是说，如果第$t$棵树的结构确定下来了，那么叶子节点的输出也可以按照上式直接计算出来。</p>
<p>我们将$w$代入损失函数：
$$L(\phi_t)=-\frac{1}{2}\sum_{j=1}^T \frac{(\sum_{i\in I_j} g_i)^2}{\lambda+\sum_{i\in I_j}h_i}+\gamma T$$
上式给出了一个确定结构的回归树加入后整个模型的损失函数，我们需要构造一棵最小化上式的树。</p>
<p>我们考虑迭代方式构造树，从根节点开始尝试对叶子结点增加分支，假如对叶子结点$j$增加分支，对映射到该结点的样本再进行划分，将$I_j$划分为$I_l$和$I_r$，作为新的两个叶子结点，而其余结点没有变化，那么新树的损失函数为：
$$L_{new}=\gamma + L +\frac{1}{2}\Big(\frac{(\sum_{i\in I_j} g_i)^2}{\lambda+\sum_{i\in I_j}h_i}-\frac{(\sum_{i\in I_l} g_i)^2}{\lambda+\sum_{i\in I_l}h_i}-\frac{(\sum_{i\in I_r} g_i)^2}{\lambda+\sum_{i\in I_r}h_i}\Big)$$
显然，我们希望划分后产生的新树的损失函数最小，实际上就是要找到一个最优的划分，使得上式最小化，如果把对应结点的式子看作该结点的score，那么就是需要新结点的score之和最大。如果上式最小化后，$L_{new}&gt;=L$，则显然在结点$j$处不可再划分了。</p>
<p>一种简单的划分办法就是遍历所有可能的划分点，假设输入的样本$x$具有$d$维的特征，一共有$n$个样本，那么对每一种特征，首先对其进行排序，而后遍历这$n$个样本的$n-1$种划分，计算新树的score，确定最优划分点。时间复杂度为$O(dnlgn)$。这种算法比较精确，当然比较慢，有一些近似算法可以给出一些划分点的proposal以减少遍历的次数，不过比较复杂这里就不阐述了。</p>
<p>以上是xgboost（实际上是gradient boosting tree）的基本思想，通过上述算法即可针对样本集构造出一个集成树模型，后续就是系统实现的问题了，本文不涉及。</p>

        </div>

        <div class="row middle-xs">
          <div class="col-xs-12">
            
            <div class="post-category">
              <a href="/categories/algorithm/">
                algorithm
              </a>
            </div>
            
          </div>
        </div>
        
          <div class="row">
            <div class="col-xs-12">
              
            </div>
          </div>

          



          
          
          <div style="height: 50px;"></div>
          
        

        <div class="site-footer">
  
  
</div>

      </div>
    </div>
  </article>

  

<script>
  
  
    
    
  
</script>

  

</body>

</html>